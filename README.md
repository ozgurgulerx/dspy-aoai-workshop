





# ðŸ§  DSPy AOAI Workshop ðŸš€ by OzgurGuler
### Programming, Not Prompting: Transform Your LLM Development Experience with DSPy

---

![GitHub stars](https://img.shields.io/github/stars/ozgurgulerx/dspy-aoai-workshop)
![GitHub forks](https://img.shields.io/github/forks/ozgurgulerx/dspy-aoai-workshop)
![License](https://img.shields.io/github/license/ozgurgulerx/dspy-aoai-workshop)
![GitHub last commit](https://img.shields.io/github/last-commit/ozgurgulerx/dspy-aoai-workshop)
![Jupyter Notebook percentage](https://img.shields.io/github/languages/top/ozgurgulerx/dspy-aoai-workshop?label=jupyter%20notebook)

---
## ðŸ“‘ Table of Contents
- [DSPy Theory](./content/0.dspy-theory.ipynb)
- [Setting up DSPy for AOAI](./content/setting-dspy-aoai.ipynb)
- [DSPy Evaluations](./content/dspy-evals.ipynb)
- [DSPy Signatures & Modules](./content/dspy-signatures-modules.ipynb)
- [DSPy RAG with AI Search](./content/dspy-rag-with-aisearch.ipynb)
- [DSPy Optimiser Basics](./content/dspy-optimisers-basics.ipynb)
- [DSPy Advanced Optimisers](./content/dspy-advanced-optimizers-miprov2.ipynb)
- [DSPy with Agency](./content/dspy-with-agency.ipynb)
- [DSPy Project01](./content/dspy-project01.ipynb)
- [DSPy Project02](./content/dspy-project02.ipynb)
---

## ðŸŽ¯ **Workshop Overview**

Welcome to the **DSPy AOAI Workshop**! This hands-on workshop is designed for AI practitioners and developers who want to explore **DSPy**â€”a revolutionary framework aiming to become the **PyTorch for LLM Programming**. Say goodbye to prompt engineering guesswork and step into a world of structured, programmatic control over large language models.

In this workshop, youâ€™ll learn how to harness DSPyâ€™s potential to **enhance Azure OpenAI (AOAI) applications** by creating reusable, modular code that simplifies the way we interact with language models.

---

## ðŸŒ **About DSPy**

**DSPy** is an emerging toolset that allows developers to move from prompt-based interactions with language models to a more **programmatic and modular approach**. Just as **PyTorch** revolutionized deep learning workflows, DSPy promises to bring a similar transformation to large language model programming by:
- ðŸ“ Enabling structured programming for model responses
- ðŸ§© Supporting modular code over complex prompts
- ðŸŽ¯ Providing a clear separation between intent and implementation

---

## ðŸŽ“ **What Youâ€™ll Learn in This Workshop**

This workshop will guide you through:
1. **The Core Concepts of DSPy**: Learn DSPyâ€™s foundational principles and understand how it differs from traditional prompt engineering.
2. **Programming AOAI with DSPy**: Develop scalable and structured LLM programs on Azure OpenAI.
3. **Real-World Use Cases**: Build and explore a customer use case, improving GPT-4O-mini outcomes through DSPy.
4. **Best Practices**: Explore DSPy best practices for efficient and reusable LLM programming in production.

---

## âš™ï¸ **Workshop Prerequisites**

- Basic familiarity with **Python** and **Jupyter Notebooks** ðŸ
- Experience with **Azure OpenAI** and language models ðŸ§ 
- Enthusiasm for **learning new paradigms** in LLM development ðŸš€

---

## ðŸ“œ **Workshop Structure**

1. **Introduction to DSPy**: Theory and fundamentals of structured LLM programming.
2. **Hands-On Labs**: Practical exercises to deepen your understanding of DSPy on AOAI.
3. **Advanced Concepts**: Tips for optimizing DSPy workflows for real-world applications.
4. **Q&A and Wrap-Up**: Addressing questions, best practices, and advanced use cases.

---

## ðŸš€ **Get Started**

1. Clone this repository:
   ```bash
   git clone https://github.com/ozgurgulerx/dspy-aoai-workshop.git
Install dependencies:
bash
Copy code
pip install -r requirements.txt
Follow along with the Jupyter Notebooks provided.

## ðŸ“¢ **Feedback and Contributions**

This workshop is a live project, and weâ€™d love your feedback! Please feel free to open issues or contribute ideas to make it even better.

> **Note**: DSPy is a cutting-edge framework, and we're excited to explore this journey with you. Your insights are invaluable in shaping the future of LLM programming.

